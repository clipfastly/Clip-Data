
// Sliding_Window_protocols


#include<stdio.h>
int main(){
    int w,i,f,frames[50];
    printf("Enter window size: ");
    scanf("%d",&w);
    printf("\nEnter number of frames to transmit: ");
    scanf("%d",&f);
    printf("\nEnter %d frames: ",f);
        for(i=1;i<=f;i++)
            scanf("%d",&frames[i]);
            printf("\nWith sliding window protocol the frames will be sent in the following manner (assuming no corruption of frames)\n\n");
            printf("After sending %d frames at each stage sender waits for acknowledgement sent by the receiver\n\n",w);
                for(i=1;i<=f;i++)
                            {
                            if(i%w==0)
                                {
                                printf("%d\n",frames[i]);
                                printf("Acknowledgement of above frames sent is received by sender\n\n");
                                    }
                                else
                                    printf("%d ",frames[i]);
                                        }
                                    if(f%w!=0)
                                        printf("\nAcknowledgement of above frames sent is received by sender\n");
                    return 0;
                                }


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


// Go Back N



#include<stdio.h>
int main(){
int w, s=0, ack, i;
    printf("enter window size\n");
    scanf("%d",&w);
    while(1){
        for(i = 0; i<w; i++){
            printf("Frame %d has been transmitted.\n",s);
                s++;
            if(s == w)
                break;
                    }
            printf("\nPlease enter the last Acknowledgement received.\n");
            scanf("%d",&ack);
                    if(ack == w)
                        break;
                    else
                        s = ack;
                        }
return 0;
                    }


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


// Client Program

#include <netdb.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/socket.h>
#include <fcntl.h> // for open
#include <unistd.h> // for close
#include <arpa/inet.h>

#define MAX 80
#define PORT 8080
#define SA struct sockaddr
void func(int sockfd)
{
    char buff[MAX];
    int n;
    for (;;) {
        bzero(buff, sizeof(buff));
        printf("Enter the string : ");
        n = 0;
        while ((buff[n++] = getchar()) != '\n')
            ;
        write(sockfd, buff, sizeof(buff));
        bzero(buff, sizeof(buff));
        read(sockfd, buff, sizeof(buff));
        printf("From Server : %s", buff);
        if ((strncmp(buff, "exit", 4)) == 0) {
            printf("Client Exit...\n");
            break;
        }
    }
}
   
int main()
{
    int sockfd, connfd;
    struct sockaddr_in servaddr, cli;
   
    // socket create and verification
    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd == -1) {
        printf("socket creation failed...\n");
        exit(0);
    }
    else
        printf("Socket successfully created..\n");
    bzero(&servaddr, sizeof(servaddr));
   
    // assign IP, PORT
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = inet_addr("127.0.0.1");
    servaddr.sin_port = htons(PORT);
   
    // connect the client socket to server socket
    if (connect(sockfd, (SA*)&servaddr, sizeof(servaddr)) != 0) {
        printf("connection with the server failed...\n");
        exit(0);
    }
    else
        printf("connected to the server..\n");
   
    // function for chat
    func(sockfd);
   
    // close the socket
    close(sockfd);
}


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

// Server Program

#include <stdio.h>
#include <netdb.h>
#include <netinet/in.h>
#include <stdlib.h>
#include <string.h>
#include <sys/socket.h>
#include <sys/types.h>
#include <fcntl.h> 
#include <unistd.h> 
#define MAX 80
#define PORT 8080
#define SA struct sockaddr
void func(int connfd)
{
    char buff[MAX];
    int n;
    for (;;) {
        bzero(buff, MAX);
        read(connfd, buff, sizeof(buff));
        printf("From client: %s\t To client : ", buff);
        bzero(buff, MAX);
        n = 0;
        while ((buff[n++] = getchar()) != '\n');
        write(connfd, buff, sizeof(buff));
        if (strncmp("exit", buff, 4) == 0) {
            printf("Server Exit...\n");
            break;
        }
    }
}
int main()
{
    int sockfd, connfd, len;
    struct sockaddr_in servaddr, cli;
    sockfd = socket(AF_INET, SOCK_STREAM, 0);
    if (sockfd == -1) {
        printf("socket creation failed...\n");
        exit(0);
    }
    else
        printf("Socket successfully created..\n");
    bzero(&servaddr, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);
    servaddr.sin_port = htons(PORT);
    if ((bind(sockfd, (SA*)&servaddr, sizeof(servaddr))) != 0) {
        printf("socket bind failed...\n");
        exit(0);
    }
    else
        printf("Socket successfully binded..\n");
    if ((listen(sockfd, 5)) != 0) {
        printf("Listen failed...\n");
        exit(0);
    }
    else
        printf("Server listening..\n");
    len = sizeof(cli);
    connfd = accept(sockfd, (SA*)&cli, &len);
    if (connfd < 0) {
        printf("server accept failed...\n");
        exit(0);
    }
    else
        printf("server accept the client...\n");
    func(connfd);
    close(sockfd);
}


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------



#8.  Decision Based IDE3


from sklearn.tree import DecisionTreeClassifier # type: ignore
from sklearn.preprocessing import LabelEncoder # type: ignore
import pandas as pd # type: ignore


# Read dataset
data = pd.read_csv('m.csv')
print("First 5 values of data:\n", data.head())

# Split input (X) and output (y)
x = data.iloc[:, :-1].copy()   # all columns except last
y = data.iloc[:, -1]           # last column (PlayTennis)
print("\nValues of X:\n", x.head())
print("\nFirst 5 values of y:\n", y.head())

# Create label encoders for each column
le_Outlook = LabelEncoder()
le_Temperature = LabelEncoder()
le_Humidity = LabelEncoder()
le_Windy = LabelEncoder()
le_PlayTennis = LabelEncoder()

# Encode input features (convert strings to numbers)
x['Outlook'] = le_Outlook.fit_transform(x['Outlook'])
x['Temperature'] = le_Temperature.fit_transform(x['Temperature'])
x['Humidity'] = le_Humidity.fit_transform(x['Humidity'])
x['Windy'] = le_Windy.fit_transform(x['Windy'])

# Encode output labels
y = le_PlayTennis.fit_transform(y)

print("\nEncoded train data X:\n", x.head())
print("\nEncoded train output y:\n", y)

# Build Decision Tree using ID3 (entropy)
classifier = DecisionTreeClassifier(criterion='entropy')
classifier.fit(x, y)

# New test input
inp = ["overcast", "cool", "normal", "strong"]
inp_df = pd.DataFrame([inp],
                    columns=['Outlook', 'Temperature', 'Humidity', 'Windy'])

# Encode test input using same encoders
inp_df['Outlook'] = le_Outlook.transform(inp_df['Outlook'])
inp_df['Temperature'] = le_Temperature.transform(inp_df['Temperature'])
inp_df['Humidity'] = le_Humidity.transform(inp_df['Humidity'])
inp_df['Windy'] = le_Windy.transform(inp_df['Windy'])

# Predict and convert back to label
y_pred = classifier.predict(inp_df)
predicted_label = le_PlayTennis.inverse_transform(y_pred)[0]

print("\nFor input {0} we obtain {1}".format(inp, predicted_label))


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#9. Email Binary Classifier


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# 1. Load dataset
data = pd.read_csv('emails.csv')
print("Dataset Head:\n", data.head())

# 2. Encode target labels (Spam = 1, Not Spam = 0)
label_encoder = LabelEncoder()
data['Prediction'] = label_encoder.fit_transform(data['Prediction'])

# 3. Drop unnecessary column
data = data.drop(columns=['Email No.'])

# 4. Split into Features (X) and Target (y)
X = data.drop(columns=['Prediction'])
y = data['Prediction']

# 5. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 6. Feature Scaling (required for both KNN & SVM)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 7. Train K-Nearest Neighbors (KNN)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

# 8. Train Support Vector Machine (SVM)
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)

# 9. Evaluation Function
def evaluate_model(y_test, y_pred, name):
    print(f"\n{name} Performance:")
    print("Accuracy :", accuracy_score(y_test, y_pred))
    print("Precision:", precision_score(y_test, y_pred))
    print("Recall   :", recall_score(y_test, y_pred))
    print("F1 Score :", f1_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 10. Print Results for Both Models
evaluate_model(y_test, y_pred_knn, "K-Nearest Neighbors (KNN)")
evaluate_model(y_test, y_pred_svm, "Support Vector Machine (SVM)")


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#10. Bank Customer


# 0. Import required libraries
import pandas as pd # type: ignore
import numpy as np # type: ignore
import matplotlib.pyplot as plt # type: ignore
import seaborn as sns # type: ignore

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier

# 1. Read the dataset
data = pd.read_csv("Churn_Modelling.csv")
print("First 5 rows:\n", data.head())

# (optional) Check missing values
print("\nMissing values in each column:\n", data.isnull().sum())

# 2. Handle categorical variables (Geography, Gender) using one-hot encoding
data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)

# 3. Distinguish feature set (X) and target set (y)
X = data.drop(columns=['Exited', 'CustomerId', 'Surname'])
y = data['Exited']   # 1 = Churn, 0 = No Churn

# 4. Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 5. Normalize the train and test data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. Initialize and build the neural network model (MLPClassifier)
# Improvement points: multiple hidden layers, ReLU activation, Adam optimizer, scaled data
model = MLPClassifier(
    hidden_layer_sizes=(128, 64, 32),
    activation='relu',
    solver='adam',
    max_iter=1000,
    random_state=42
)

# 7. Train the model
model.fit(X_train_scaled, y_train)

# 8. Predict on the test set
y_pred = model.predict(X_test_scaled)

# 9. Print the accuracy score
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy * 100:.2f}%")

# 10. Print the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# 11. Visualize the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(
    cm,
    annot=True,
    fmt='d',
    cmap='Blues',
    xticklabels=['No Churn', 'Churn'],
    yticklabels=['No Churn', 'Churn']
)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()


-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


#11.  Gradient descent algo


import numpy as np
import matplotlib.pyplot as plt

# Function: y = (x + 3)^2
def func(x):
    return (x + 3) ** 2

# Derivative of the function: dy/dx = 2(x + 3)
def grad_func(x):
    return 2 * (x + 3)

# Gradient Descent Algorithm
def gradient_descent(starting_point, learning_rate, num_iterations):
    x = starting_point
    x_history = [x]  # store all x values to plot the path

    for _ in range(num_iterations):
        gradient = grad_func(x)               # compute slope at current x
        x = x - learning_rate * gradient      # move opposite to slope
        x_history.append(x)                   # save new x

    return x, x_history

# Parameters
starting_point = 2       # start at x = 2
learning_rate = 0.1      # step size
num_iterations = 20      # number of updates

# Run gradient descent
final_x, x_history = gradient_descent(starting_point, learning_rate, num_iterations)

print(f"Final x after {num_iterations} iterations: {final_x}")
print(f"Minimum value of function: {func(final_x)}")

# Plot function and descent path
x_vals = np.linspace(-10, 5, 100)
y_vals = func(x_vals)

plt.figure(figsize=(8, 6))
plt.plot(x_vals, y_vals, label='y = (x + 3)^2')
plt.scatter(x_history, [func(x) for x in x_history], color='red', label='Descent path')
plt.plot(x_history, [func(x) for x in x_history], color='red', linestyle='dashed', alpha=0.6)
plt.title('Gradient Descent to Find Local Minimum')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.grid(True)
plt.show()

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#12. KNN Diabeties


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score

# 1. Load dataset
dataset = pd.read_csv("diabetes.csv")
print("Dataset Loaded Successfully")

# 2. Preprocess data (fill missing values if any)
dataset.fillna(dataset.median(), inplace=True)

# 3. Create feature matrix (X) and target vector (y)
X = dataset.drop("Outcome", axis=1)   # all columns except Outcome
y = dataset["Outcome"]                # 1 = diabetic, 0 = not diabetic

# 4. Train-test split (70% training, 30% testing)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 5. Train KNN classifier
knn = KNeighborsClassifier(n_neighbors=5)  # K = 5
knn.fit(X_train, y_train)

# 6. Predict the output
y_pred = knn.predict(X_test)

# 7. Compute evaluation metrics
cm = confusion_matrix(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)
error_rate = 1 - accuracy
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# 8. Print results
print("\nConfusion Matrix:\n", cm)
print("Accuracy      :", accuracy)
print("Error Rate    :", error_rate)
print("Precision     :", precision)
print("Recall        :", recall)

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#13. K means clustering


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# 1. Load the dataset
# If file is in same folder, just use: "sales_data_sample.csv"
data = pd.read_csv("sales_data_sample.csv", encoding="latin1")
print("Columns in dataset:\n", data.columns)

# 2. Select relevant numeric columns for clustering
# Use the actual column names present in your CSV
data_selected = data[['QUANTITYORDERED', 'PRICEEACH', 'SALES']]

# 3. Handle missing values (if any)
data_selected = data_selected.fillna(data_selected.mean())

# 4. Normalize (standardize) the data
scaler = StandardScaler()
data_normalized = scaler.fit_transform(data_selected)

# 5. Elbow Method to find optimal number of clusters (k)
inertia = []
K_range = range(1, 11)  # Try k from 1 to 10

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(data_normalized)
    inertia.append(kmeans.inertia_)  # sum of squared distances to cluster center

# Plot the Elbow curve
plt.figure(figsize=(8, 6))
plt.plot(K_range, inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia (Within-cluster sum of squares)')
plt.grid(True)
plt.show()

# 6. Choose k based on Elbow (example: k = 4)
optimal_k = 4  # replace this after seeing elbow plot

# 7. Apply K-Means with optimal_k
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
kmeans_labels = kmeans.fit_predict(data_normalized)

# Add cluster labels to original data
data['KMeans_Cluster'] = kmeans_labels

# 8. Visualize clusters (Sales vs Quantity Ordered)
plt.figure(figsize=(8, 6))
plt.scatter(
    data['SALES'],
    data['QUANTITYORDERED'],
    c=data['KMeans_Cluster'],
    cmap='viridis'
)
plt.title('K-Means Clustering (Sales vs Quantity Ordered)')
plt.xlabel('Sales')
plt.ylabel('Quantity Ordered')
plt.grid(True)
plt.show()



-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

